{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIbogPXyM0wr"
      },
      "source": [
        "# Interview Prep Tool"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x_Vp8SiKM4p1"
      },
      "source": [
        "## Problem Definition\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o_60X8H3NEne"
      },
      "source": [
        "## Libraries\n",
        "\n",
        "This section will install and import some important libraries such as Langchain, openai, Gradio, and so on"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "pxcqXgg2aAN7"
      },
      "outputs": [],
      "source": [
        "# # install libraries here\n",
        "# # -q flag for \"quiet\" install\n",
        "# %%capture\n",
        "# !pip install -q langchain\n",
        "# !pip install -q openai\n",
        "# !pip install -q gradio\n",
        "# !pip install -q torchaudio\n",
        "# !pip install -q git+https://github.com/openai/whisper.git\n",
        "# !pip install -q docx\n",
        "# !pip install -q PyPDF2\n",
        "# !pip install -q python-docx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pEjM1tLsMZBq"
      },
      "outputs": [],
      "source": [
        "# import libraries here\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain import PromptTemplate\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "import openai\n",
        "import os\n",
        "from getpass import getpass\n",
        "import whisper\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import gradio as gr\n",
        "from docx import Document\n",
        "import PyPDF2\n",
        "from pydub import AudioSegment\n",
        "import tempfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03KLZGI_a5W5"
      },
      "source": [
        "## API Keys\n",
        "\n",
        "Use these cells to load the API keys required for this notebook. The below code cell uses the `getpass` library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5smcWj4DbFgy",
        "outputId": "9c43b5b8-50f6-40eb-ac79-b3bc927ff750"
      },
      "outputs": [],
      "source": [
        "openai_api_key = getpass()\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "openai.api_key = openai_api_key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgnCZRMhADvo",
        "outputId": "9d865cb9-3ec0-4528-84ac-3ff65daa4127"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x16c1df3d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x16d945150>, temperature=0.0, openai_api_key='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', openai_proxy='')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat = ChatOpenAI(temperature=0.0, model_name='gpt-3.5-turbo')\n",
        "chat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMo9x8u4AEV1"
      },
      "source": [
        "## Prompt Design"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5vWxcm25EAC"
      },
      "source": [
        "### Prompt for Question Generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDq3Azda4Xc8",
        "outputId": "143ba8ef-c3c1-41e9-f69a-71c7d9a366a8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['guideline', 'resume']"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The prompt used for 'generate_interview_questions'\n",
        "prompt_QA = \"\"\"\n",
        "You are a world-class career coach helping students to perform better on the job interview.\n",
        "One of your job is to tailor the interview questions based on the student's profile and the frequently asked questions.\n",
        "\n",
        "Input Information:\n",
        "\n",
        "Student Profile: The student's resume is provided as input. This includes their educational background, work experience, skills, and any relevant projects or extracurricular activities. Use this information to understand the student's strengths and areas for improvement.\n",
        "Guideline Questions: A list of frequently asked questions in job interviews is available for reference. If no specific guideline is provided, rely on your professional judgment to formulate relevant questions.\n",
        "\n",
        "The following text contains the basic information about the studnet profile: {resume} \\\n",
        "The following is the some of the examples of the frequently asked questions: {guideline}; \\\n",
        "\n",
        "Task:\n",
        "\n",
        "Generate a set of 10 interview questions that are specifically designed for the student, based on their profile and the guideline questions.\n",
        "The questions should be diverse, covering different aspects such as technical skills, soft skills, problem-solving abilities, and situational responses.\n",
        "\n",
        "Based on all the infomation, please design 10 questions based on the student profile and frequently asked questions.\" \\\n",
        "\n",
        "The output should be formatted as following:\n",
        "\n",
        "Question 1: ...\n",
        "Question 2: ...\n",
        "Question 3: ...\n",
        "...\n",
        "\"\"\"\n",
        "\n",
        "question_template = ChatPromptTemplate.from_template(prompt_QA)\n",
        "question_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2tTNiyU-ZcDU"
      },
      "source": [
        "### Chatbot Prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-VmK_7vHrmw",
        "outputId": "9f851500-42b1-4e85-9afd-264701065732"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['history', 'input', 'instruction', 'questions']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# The prompot used for 'bot_initialize'\n",
        "template_string = \"\"\"\n",
        "Please ask me the following questions in sequence, and after I provide the answer, \\\n",
        "please give me some feedback. Here is the instruction for feedback: {instruction}. If no instruction is provided, please provide feedback based on your judgement. \\\n",
        "Just ask me the question, and please do not show any other text (no need for greetings for example) \\\n",
        "Here are the questions that you can will me: {questions}. \\\n",
        "Here are the chat history: {history}. \\\n",
        "{input}\n",
        "\n",
        "Once all questions are answered, thank the user and give overall feedback for the question answering part.\"\"\"\n",
        "prompt_template = ChatPromptTemplate.from_template(template_string)\n",
        "prompt_template.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DMTybR3PVuoC"
      },
      "source": [
        "### Creating a prompt for AI Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMzIN5IiUTSl",
        "outputId": "e85e65f0-7942-4d49-cde6-cea5c534e094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['QA', 'context', 'instructions']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# prompt used for 'ai_evaluate_interview'\n",
        "template_evaluation_oral = \"\"\"\n",
        "Given\n",
        "1. The follwing is the context of the interview: {context} \\\n",
        "\n",
        "2. The Questions asked to the student and student answers {QA} \\\n",
        "\n",
        "Please evaluate the students performance based on {instructions} \\\n",
        "\n",
        "If no instruction is provided, you can evaluate based on your judgement of the students performance.\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "evaluate_template_oral = ChatPromptTemplate.from_template(template_evaluation_oral)\n",
        "evaluate_template_oral.messages[0].prompt.input_variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4o8R5eUE1n8"
      },
      "source": [
        "## Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ABN0X9xQHeii"
      },
      "outputs": [],
      "source": [
        "def embed_key(openai_api_key):\n",
        "  os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
        "\n",
        "\n",
        "def process_file(files):\n",
        "  for file in files:\n",
        "    try:\n",
        "        extension = file.name.split('.')[-1].lower()\n",
        "        if extension == 'docx':\n",
        "            doc = Document(file.name)\n",
        "            full_text = []\n",
        "            for paragraph in doc.paragraphs:\n",
        "                full_text.append(paragraph.text)\n",
        "            return '\\n'.join(full_text)\n",
        "\n",
        "        elif extension == 'pdf':\n",
        "            pdf_file = open(file.name, 'rb')\n",
        "            reader = PyPDF2.PdfReader(pdf_file)\n",
        "            num_pages = len(reader.pages)\n",
        "            full_text = []\n",
        "            for page in range(num_pages):\n",
        "                page_obj = reader.pages[page]\n",
        "                full_text.append(page_obj.extract_text())\n",
        "            pdf_file.close()\n",
        "            return '\\n'.join(full_text)\n",
        "\n",
        "        elif extension == 'txt':\n",
        "            with open(file.name, 'r') as txt_file:\n",
        "                full_text = txt_file.read()\n",
        "            return full_text\n",
        "\n",
        "        else:\n",
        "            return \"Unsupported file type\"\n",
        "    except FileNotFoundError:\n",
        "        return \"File not found\"\n",
        "    except PermissionError:\n",
        "        return \"Permission denied\"\n",
        "\n",
        "def generate_interview_questions(text, prompt):\n",
        "    test_input1 = question_template.format_messages(\n",
        "                      resume = text,\n",
        "                      guideline = prompt)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "\n",
        "def ai_evaluate_interview(context, QA, instructions):\n",
        "    test_input1 = evaluate_template_oral.format_messages(\n",
        "                      context = context,\n",
        "                      QA = QA,\n",
        "                      instructions = instructions)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "def upload_file(files):\n",
        "    file_paths = [file.name for file in files]\n",
        "    return file_paths\n",
        "\n",
        "def use_these_questions(input):\n",
        "    return input\n",
        "\n",
        "\n",
        "def add_text(history, text, prompt = template_string):\n",
        "    new_history = [(prompt, None)] + history + [(text, None)]\n",
        "    return new_history, gr.update(value=\"\", interactive=False)\n",
        "\n",
        "\n",
        "def bot_initialize(input, instruction_feedback, questions_used, history):\n",
        "    test_input1 = prompt_template.format_messages(\n",
        "                      instruction = instruction_feedback,\n",
        "                      history = history,\n",
        "                      questions = questions_used,\n",
        "                      input = input)\n",
        "\n",
        "    response = chat(test_input1)\n",
        "    return response.content\n",
        "\n",
        "\n",
        "def message_and_history(input, instruction_feedback, questions_used, history):\n",
        "    history = history or []\n",
        "    s = list(sum(history, ()))\n",
        "    s.append(input)\n",
        "    inp = ' '.join(s)\n",
        "    output = bot_initialize(inp, instruction_feedback, questions_used, history)\n",
        "    history.append((input, output))\n",
        "    return history, history\n",
        "\n",
        "def transcribe(audio_file_path):\n",
        "  try:\n",
        "    with open(audio_file_path, \"rb\") as audio_file:\n",
        "      # Call OpenAI's Whisper model for transcription\n",
        "      model = whisper.load_model(\"base\")\n",
        "      result = model.transcribe(audio_file_path)\n",
        "      return result[\"text\"]\n",
        "  except:\n",
        "    return \"Your answer will be transcribed here\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6IzVTjz5cex"
      },
      "source": [
        "## UI Design\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDsNxoKBu45t"
      },
      "source": [
        "### Interview Assitance V1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "id": "uQH0kAYCu9wf",
        "outputId": "de3582cd-0806-4cb7-ad8a-b417d502592f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with gr.Blocks() as demo:\n",
        "  # Title and API key section\n",
        "  gr.Markdown(\"# Oral Exam App\") # Heading for the application\n",
        "  gr.Markdown(\"## OpenAI API key\")\n",
        "  # Instructions for embedding OpenAI API key\n",
        "  gr.HTML(\"\"\"Embed your OpenAI API key below; if you haven't created one already, visit\n",
        "          platform.openai.com/account/api-keys\n",
        "          to sign up for an account and get your personal API key\"\"\",\n",
        "          elem_classes=\"textbox_label\")\n",
        "  input = gr.Textbox(show_label=False, type=\"password\", container=False,\n",
        "                  placeholder=\"●●●●●●●●●●●●●●●●●\")\n",
        "  input.change(fn=embed_key, inputs=input, outputs=None)\n",
        "  \n",
        "  # Context section for uploading documents relevant to the interview i.e resume\n",
        "  with gr.Blocks():\n",
        "      with gr.Accordion(\"Context section\"):\n",
        "          gr.Markdown(\"## Please upload your resume or relevant documents for the interview\")\n",
        "          context_input = gr.File(label=\"Click to upload context file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          outputs_context=gr.Textbox(label=\"Context\")\n",
        "          context_input.change(fn=process_file, inputs=context_input, outputs=outputs_context)\n",
        "\n",
        "\n",
        "      # Question Generation section\n",
        "      with gr.Accordion(\"Question section\"):\n",
        "          gr.Markdown(\"## Questions\")\n",
        "\n",
        "          instruction_qa_input = gr.File(label=\"Click to upload instruction file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          instruction_qa_output=gr.Textbox(label=\"Context\")\n",
        "          instruction_qa_input.change(fn=process_file, inputs=instruction_qa_input, outputs=instruction_qa_output)\n",
        "\n",
        "\n",
        "\n",
        "          with gr.Row():\n",
        "            with gr.Column():\n",
        "                outputs_qa=gr.Textbox(label=\"Generate questions\")\n",
        "                btn1 = gr.Button(value= \"Generate questions\")\n",
        "\n",
        "\n",
        "                btn1.click(generate_interview_questions,\n",
        "                                    inputs=[outputs_context,instruction_qa_output],\n",
        "                                    outputs=outputs_qa)\n",
        "    \n",
        "\n",
        "      # Evaluation Metrics section\n",
        "      with gr.Accordion(\"Evaluation Metrics Section\"):\n",
        "          gr.Markdown(\"## Evaluation Metrics\")\n",
        "\n",
        "          evaluation_input = gr.File(label=\"Click to upload evaluation file\",\n",
        "                                  file_count=\"multiple\",\n",
        "                                  file_types=[\".txt\", \".docx\", \".pdf\"])\n",
        "          evaluation_output=gr.Textbox(label=\"Context\")\n",
        "          evaluation_input.change(fn=process_file, inputs=evaluation_input, outputs=evaluation_output)\n",
        "\n",
        "        \n",
        "\n",
        "      # Audio QA section for recording and transcribing answers\n",
        "      with gr.Accordion(\"Audio QA section\"):\n",
        "          gr.Markdown(\"## Question answering\")\n",
        "          gr.Markdown(\"### When you are ready to answer questions, press the 'I am ready' button\")\n",
        "          ##### This may be iterative\n",
        "          chatbot = gr.Chatbot([],\n",
        "                                  elem_id=\"chatbot\",\n",
        "                                  height=300)\n",
        "\n",
        "          ready_button = gr.Button(value=\"I am ready\")\n",
        "\n",
        "          state = gr.State()\n",
        "          message = gr.Textbox(show_label=False,\n",
        "                              placeholder=\"Your answer will be transcribed here\",\n",
        "                              container=False)\n",
        "\n",
        "          ready_button.click(message_and_history, inputs=[message, evaluation_output, outputs_qa, state], outputs=[chatbot, state])\n",
        "\n",
        "          hidden = gr.Textbox(visible = False)\n",
        "          btn_record = gr.Audio(label=\"Record Audio\", sources=\"microphone\", type=\"filepath\")\n",
        "          btn_record.change(fn=transcribe, inputs=btn_record, outputs=message)\n",
        "          btn_record.clear(use_these_questions, inputs = hidden, outputs = message)\n",
        "\n",
        "          submit = gr.Button(\"Submit\")\n",
        "          submit.click(message_and_history,\n",
        "                      inputs=[message, evaluation_output, outputs_qa, state],\n",
        "                      outputs=[chatbot, state])\n",
        "\n",
        "          message_records = gr.Textbox(show_label=False,\n",
        "                              container=False)\n",
        "          show_records = gr.Button(\"Show QA history\")\n",
        "          show_records.click(use_these_questions,\n",
        "                      inputs=state,\n",
        "                      outputs=message_records)\n",
        "\n",
        "      # Evaluation section for analyzing interview performance\n",
        "      with gr.Accordion(\"Evaluation section\"):\n",
        "          gr.Markdown(\"## Evaluation\")\n",
        "          with gr.Tab(\"General evalution\"):\n",
        "            evalution=gr.Textbox(label=\"AI Evaluation\")\n",
        "            btn5 = gr.Button(value=\"Evaluate\")\n",
        "            btn5.click(ai_evaluate_interview, inputs=[outputs_context, message_records, instruction_qa_output], outputs=evalution)\n",
        "  \n",
        "  # Launch the Gradio application with debugging enabled\n",
        "  demo.launch(debug=True)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
